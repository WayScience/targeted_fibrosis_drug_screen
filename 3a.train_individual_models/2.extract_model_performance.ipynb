{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract model performance metrics\n",
    "\n",
    "In this notebook, we extract metrics to evaluate performance such as:\n",
    "\n",
    "1. Precision-recall\n",
    "2. Predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "from joblib import load\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from training_utils import get_X_y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper function to collect precision-recall results and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pr_curve_results(\n",
    "    model: LogisticRegression, df: pd.DataFrame, label: str, label_encoder: LabelEncoder\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Collect the precision-recall curve results from a model and dataset.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegression): loaded in logistic regression model to collect results from\n",
    "        df (pd.DataFrame): dataframe containing the data to apply model to\n",
    "        label (str): label with the class being predicted\n",
    "        label_encoder (LabelEncoder): encoder to transform the labels to integers\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with the PR curve results for that data and model\n",
    "    \"\"\"\n",
    "    # Get X and y data for the model\n",
    "    X, y = get_X_y_data(df=df, label=label, shuffle=False)\n",
    "\n",
    "    assert all(col in model.feature_names_in_ for col in X), \\\n",
    "        \"Features in the model do not match the columns in the dataset\"\n",
    "\n",
    "    y_encoded = label_encoder.transform(y)\n",
    "    y_scores = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(y_encoded, y_scores)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"precision\": precision[:-1],  # remove last to align with thresholds\n",
    "        \"recall\": recall[:-1],\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_probabilities(\n",
    "    model: LogisticRegression, df: pd.DataFrame, label: str, label_encoder: LabelEncoder\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"Collect predicted probabilities per single-cell from the model and dataset.\n",
    "\n",
    "    Args:\n",
    "        model (LogisticRegression): loaded in logistic regression model to collect results from\n",
    "        df (pd.DataFrame): dataframe containing the data to apply model to\n",
    "        label (str): label with the class being predicted\n",
    "        label_encoder (LabelEncoder): encoder to transform the labels to integers\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe with the predicted probabilities per single-cell\n",
    "    \"\"\"\n",
    "    metadata_treatment = df[\"Metadata_treatment\"].values\n",
    "    X, y = get_X_y_data(df=df, label=label, shuffle=False)\n",
    "\n",
    "    assert all(col in model.feature_names_in_ for col in X), \\\n",
    "        \"Features in the model do not match the columns in the dataset\"\n",
    "\n",
    "    # y_encoded = label_encoder.transform(y)\n",
    "    y_scores = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"actual_label\": y,\n",
    "        \"predicted_probability\": y_scores,\n",
    "        \"Metadata_treatment\": metadata_treatment\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the training and testing datasets per plate (or combined per batch)\n",
    "data_dir = pathlib.Path(\"data\")\n",
    "\n",
    "# Directory with the trained models\n",
    "model_dir = pathlib.Path(\"models\")\n",
    "\n",
    "# Directory with encoder\n",
    "encoder_dir = pathlib.Path(\"encoder_results\")\n",
    "\n",
    "# Directory with the training indices\n",
    "train_indices_dir = pathlib.Path(\"training_indices\")\n",
    "\n",
    "# Directory with the normalized datasets\n",
    "normalized_data_path = pathlib.Path(\n",
    "    \"../3.preprocessing_features/data/single_cell_profiles\"\n",
    ")\n",
    "\n",
    "# Output directory the performance metrics\n",
    "performance_metrics_dir = pathlib.Path(\"performance_metrics\")\n",
    "performance_metrics_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Label being predicted\n",
    "label = \"Metadata_cell_type\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary with all relevant paths per plate to extract metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of encoder files\n",
    "encoder_dir = pathlib.Path(\"./encoder_results\")\n",
    "\n",
    "# Extract plate names from model filenames\n",
    "plate_names = set(\n",
    "    f.stem.replace(\"_final_downsample\", \"\")\n",
    "    for f in model_dir.glob(\"*_final_downsample.joblib\")\n",
    ")\n",
    "\n",
    "# Create a nested dictionary with info per plate\n",
    "plates_dict = {}\n",
    "for plate in plate_names:\n",
    "    plates_dict[plate] = {\n",
    "        \"training_data\": data_dir / f\"{plate}_train.parquet\",\n",
    "        \"testing_data\": data_dir / f\"{plate}_test.parquet\",\n",
    "        \"final_model\": model_dir / f\"{plate}_final_downsample.joblib\",\n",
    "        \"shuffled_model\": model_dir / f\"{plate}_shuffled_downsample.joblib\",\n",
    "        \"encoder_result\": encoder_dir / \"label_encoder_global.joblib\",\n",
    "        \"training_indices\": train_indices_dir / f\"{plate}_training_data_indices.csv\",\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract metrics from the train and testing datasets applied to their respective plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL | localhost240927120001 | train → Done\n",
      "SHUFFLED | localhost240927120001 | train → Done\n",
      "FINAL | localhost240927120001 | test → Done\n",
      "SHUFFLED | localhost240927120001 | test → Done\n",
      "FINAL | localhost240927060001 | train → Done\n",
      "SHUFFLED | localhost240927060001 | train → Done\n",
      "FINAL | localhost240927060001 | test → Done\n",
      "SHUFFLED | localhost240927060001 | test → Done\n",
      "FINAL | localhost240928120001 | train → Done\n",
      "SHUFFLED | localhost240928120001 | train → Done\n",
      "FINAL | localhost240928120001 | test → Done\n",
      "SHUFFLED | localhost240928120001 | test → Done\n",
      "FINAL | localhost240926150001 | train → Done\n",
      "SHUFFLED | localhost240926150001 | train → Done\n",
      "FINAL | localhost240926150001 | test → Done\n",
      "SHUFFLED | localhost240926150001 | test → Done\n",
      "FINAL | combined_batch1 | train → Done\n",
      "SHUFFLED | combined_batch1 | train → Done\n",
      "FINAL | combined_batch1 | test → Done\n",
      "SHUFFLED | combined_batch1 | test → Done\n",
      "(17600, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>plate_trained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.080243</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual_label  predicted_probability Metadata_treatment model_type dataset  \\\n",
       "0      failing               0.080243               DMSO      final   train   \n",
       "1      failing               0.028664               DMSO      final   train   \n",
       "\n",
       "           plate_trained  \n",
       "0  localhost240927120001  \n",
       "1  localhost240927120001  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize results list\n",
    "test_train_pr_results = []\n",
    "test_train_probability_results = []\n",
    "\n",
    "# Run through each plate and get the PR results for training and testing data only\n",
    "for plate, paths in plates_dict.items():\n",
    "    # Load the models and data\n",
    "    final_model = load(paths[\"final_model\"])\n",
    "    shuffled_model = load(paths[\"shuffled_model\"])\n",
    "    label_encoder = load(paths[\"encoder_result\"])\n",
    "    train_df = pd.read_parquet(paths[\"training_data\"])\n",
    "    test_df = pd.read_parquet(paths[\"testing_data\"])\n",
    "\n",
    "    # Filter the training data to only include the indices used in training the model\n",
    "    training_indices = pd.read_csv(paths[\"training_indices\"])[\"Index\"]\n",
    "    train_df_filtered = train_df.loc[training_indices]\n",
    "\n",
    "    # Set dictionary with the training and testing data\n",
    "    datasets = {\"train\": train_df_filtered, \"test\": test_df}\n",
    "\n",
    "    # Loop through both datasets and models\n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        for model_name, model in [(\"final\", final_model), (\"shuffled\", shuffled_model)]:\n",
    "            # Get per-sample predicted probabilities\n",
    "            prob_df = get_predicted_probabilities(\n",
    "                model=model, df=dataset, label=label, label_encoder=label_encoder\n",
    "            )\n",
    "            prob_df[\"model_type\"] = model_name\n",
    "            prob_df[\"dataset\"] = dataset_name\n",
    "            prob_df[\"plate_trained\"] = plate\n",
    "            test_train_probability_results.append(prob_df)\n",
    "\n",
    "            # Get PR curve results (global)\n",
    "            pr_df = get_pr_curve_results(\n",
    "                model=model, df=dataset, label=label, label_encoder=label_encoder\n",
    "            )\n",
    "            pr_df[\"model_type\"] = model_name\n",
    "            pr_df[\"dataset\"] = dataset_name\n",
    "            pr_df[\"plate_trained\"] = plate\n",
    "            test_train_pr_results.append(pr_df)\n",
    "\n",
    "            print(f\"{model_name.upper()} | {plate} | {dataset_name} → Done\")\n",
    "\n",
    "# Combine all results into one dataframe\n",
    "train_test_all_models_pr_results_df = pd.concat(test_train_pr_results, ignore_index=True)\n",
    "train_test_all_models_probabilities_df = pd.concat(test_train_probability_results, ignore_index=True)\n",
    "\n",
    "# Check output\n",
    "print(train_test_all_models_probabilities_df.shape)\n",
    "train_test_all_models_probabilities_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the individual plate models to the three other plates in the batch (considered holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate models being applied is: localhost240927120001\n",
      "final applied to localhost240927060001 shape: (1526, 5)\n",
      "shuffled applied to localhost240927060001 shape: (1526, 5)\n",
      "final applied to localhost240928120001 shape: (1573, 5)\n",
      "shuffled applied to localhost240928120001 shape: (1573, 5)\n",
      "final applied to localhost240926150001 shape: (2022, 5)\n",
      "shuffled applied to localhost240926150001 shape: (2022, 5)\n",
      "Plate models being applied is: localhost240927060001\n",
      "final applied to localhost240927120001 shape: (1513, 5)\n",
      "shuffled applied to localhost240927120001 shape: (1507, 5)\n",
      "final applied to localhost240928120001 shape: (1573, 5)\n",
      "shuffled applied to localhost240928120001 shape: (1573, 5)\n",
      "final applied to localhost240926150001 shape: (2021, 5)\n",
      "shuffled applied to localhost240926150001 shape: (2022, 5)\n",
      "Plate models being applied is: localhost240928120001\n",
      "final applied to localhost240927120001 shape: (1513, 5)\n",
      "shuffled applied to localhost240927120001 shape: (1512, 5)\n",
      "final applied to localhost240927060001 shape: (1525, 5)\n",
      "shuffled applied to localhost240927060001 shape: (1525, 5)\n",
      "final applied to localhost240926150001 shape: (2022, 5)\n",
      "shuffled applied to localhost240926150001 shape: (2021, 5)\n",
      "Plate models being applied is: localhost240926150001\n",
      "final applied to localhost240927120001 shape: (1512, 5)\n",
      "shuffled applied to localhost240927120001 shape: (1506, 5)\n",
      "final applied to localhost240927060001 shape: (1526, 5)\n",
      "shuffled applied to localhost240927060001 shape: (1526, 5)\n",
      "final applied to localhost240928120001 shape: (1573, 5)\n",
      "shuffled applied to localhost240928120001 shape: (1573, 5)\n",
      "Final combined Probability DataFrame shape: (39806, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>plate_trained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>healthy</td>\n",
       "      <td>0.963331</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>holdout_localhost240927060001</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>healthy</td>\n",
       "      <td>0.984123</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>holdout_localhost240927060001</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual_label  predicted_probability Metadata_treatment model_type  \\\n",
       "0      healthy               0.963331               DMSO      final   \n",
       "1      healthy               0.984123               DMSO      final   \n",
       "\n",
       "                         dataset          plate_trained  \n",
       "0  holdout_localhost240927060001  localhost240927120001  \n",
       "1  holdout_localhost240927060001  localhost240927120001  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lists to store PR curve results and predicted probabilities\n",
    "holdout_plate_individual_models_results = []\n",
    "holdout_plate_individual_models_probability_results = []\n",
    "\n",
    "# Iterate through each plate\n",
    "for plate, paths in plates_dict.items():\n",
    "    if plate == \"combined_batch1\":\n",
    "        continue  # Skip the combined_batch1 plate\n",
    "\n",
    "    # Print current plate models being applied\n",
    "    print(f\"Plate models being applied is: {plate}\")\n",
    "\n",
    "    # Load models\n",
    "    final_model = load(paths[\"final_model\"])\n",
    "    shuffled_model = load(paths[\"shuffled_model\"])\n",
    "\n",
    "    # Load encoder\n",
    "    label_encoder = load(paths[\"encoder_result\"])\n",
    "\n",
    "    # Get the feature names from the model\n",
    "    model_features = final_model.feature_names_in_\n",
    "\n",
    "    # Iterate over other plates using normalized data (holdout sets)\n",
    "    for holdout_plate in plates_dict:\n",
    "        # Skip processing for the model plate or combined_batch1\n",
    "        if holdout_plate == plate or holdout_plate == \"combined_batch1\":\n",
    "            continue\n",
    "\n",
    "        # Load in the normalized data for the holdout plate\n",
    "        holdout_normalized_path = (\n",
    "            f\"{normalized_data_path}/{holdout_plate}_sc_normalized.parquet\"\n",
    "        )\n",
    "        holdout_norm_df = pd.read_parquet(holdout_normalized_path)\n",
    "\n",
    "        # Filter out only the cells with Metadata_treatment as DMSO\n",
    "        holdout_norm_df = holdout_norm_df[\n",
    "            holdout_norm_df[\"Metadata_treatment\"] == \"DMSO\"\n",
    "        ]\n",
    "\n",
    "        # Drop rows with NaNs based on model features\n",
    "        holdout_norm_df = holdout_norm_df.dropna(subset=model_features)\n",
    "\n",
    "        # Get the metadata columns (those starting with 'Metadata_')\n",
    "        metadata_columns = [\n",
    "            col\n",
    "            for col in holdout_norm_df.columns\n",
    "            if col.startswith(\"Metadata_\")\n",
    "        ]\n",
    "\n",
    "        # Get model features from the dataframe\n",
    "        model_features_in_df = [\n",
    "            col for col in model_features if col in holdout_norm_df.columns\n",
    "        ]\n",
    "\n",
    "        # Filter the dataframe to keep only model features and metadata columns\n",
    "        holdout_norm_df = holdout_norm_df[\n",
    "            metadata_columns + model_features_in_df\n",
    "        ]\n",
    "\n",
    "        # Loop through models (final and shuffled)\n",
    "        for model_name, model in [(\"final\", final_model), (\"shuffled\", shuffled_model)]:\n",
    "            # Get predicted probabilities (per-sample) using the function\n",
    "            prob_df = get_predicted_probabilities(\n",
    "                model=model, df=holdout_norm_df, label=label, label_encoder=label_encoder\n",
    "            )\n",
    "            prob_df[\"model_type\"] = model_name\n",
    "            prob_df[\"dataset\"] = f\"holdout_{holdout_plate}\"  # Mark as holdout plate\n",
    "            prob_df[\"plate_trained\"] = plate\n",
    "            holdout_plate_individual_models_probability_results.append(prob_df)\n",
    "\n",
    "            # Get PR curve results using the function\n",
    "            pr_df = get_pr_curve_results(\n",
    "                model=model, df=holdout_norm_df, label=label, label_encoder=label_encoder\n",
    "            )\n",
    "\n",
    "            # Add context columns\n",
    "            pr_df[\"model_type\"] = model_name\n",
    "            pr_df[\"dataset\"] = f\"holdout_{holdout_plate}\"  # Mark as holdout plate\n",
    "            pr_df[\"plate_trained\"] = plate\n",
    "\n",
    "            # Append to results list for the plate\n",
    "            holdout_plate_individual_models_results.append(pr_df)\n",
    "\n",
    "            # Print the shape of pr_df per holdout plate\n",
    "            print(f\"{model_name} applied to {holdout_plate} shape: {pr_df.shape}\")\n",
    "\n",
    "# Combine all results into one dataframe for both PR results and probabilities\n",
    "holdout_plate_individual_models_pr_df = pd.concat(holdout_plate_individual_models_results, ignore_index=True)\n",
    "holdout_plate_individual_models_probability_df = pd.concat(holdout_plate_individual_models_probability_results, ignore_index=True)\n",
    "\n",
    "print(f\"Final combined Probability DataFrame shape: {holdout_plate_individual_models_probability_df.shape}\")\n",
    "holdout_plate_individual_models_probability_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the combined model to the testing dataset split by plate to evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final applied to localhost240926150001 shape: (607, 5)\n",
      "shuffled applied to localhost240926150001 shape: (607, 5)\n",
      "final applied to localhost240927060001 shape: (458, 5)\n",
      "shuffled applied to localhost240927060001 shape: (458, 5)\n",
      "final applied to localhost240927120001 shape: (454, 5)\n",
      "shuffled applied to localhost240927120001 shape: (455, 5)\n",
      "final applied to localhost240928120001 shape: (472, 5)\n",
      "shuffled applied to localhost240928120001 shape: (472, 5)\n",
      "Final combined Probability DataFrame shape: (3984, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>plate_trained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.014220</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>test_localhost240926150001</td>\n",
       "      <td>combined_batch1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.002333</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>test_localhost240926150001</td>\n",
       "      <td>combined_batch1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual_label  predicted_probability Metadata_treatment model_type  \\\n",
       "0      failing               0.014220               DMSO      final   \n",
       "1      failing               0.002333               DMSO      final   \n",
       "\n",
       "                      dataset    plate_trained  \n",
       "0  test_localhost240926150001  combined_batch1  \n",
       "1  test_localhost240926150001  combined_batch1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lists to store PR curve results and predicted probabilities\n",
    "combined_model_split_test_pr_results = []\n",
    "combined_model_split_test_probability_results = []\n",
    "\n",
    "# Only process the combined_batch1 data\n",
    "paths = plates_dict[\"combined_batch1\"]\n",
    "\n",
    "# Load models\n",
    "final_model = load(paths[\"final_model\"])\n",
    "shuffled_model = load(paths[\"shuffled_model\"])\n",
    "\n",
    "# Load encoder\n",
    "label_encoder = load(paths[\"encoder_result\"])\n",
    "\n",
    "# Load testing data\n",
    "test_df = pd.read_parquet(paths[\"testing_data\"])\n",
    "\n",
    "# Split testing data by Metadata_Plate\n",
    "test_groups = test_df.groupby(\"Metadata_Plate\")\n",
    "\n",
    "for plate, dataset in test_groups:\n",
    "    for model_name, model in [(\"final\", final_model), (\"shuffled\", shuffled_model)]:\n",
    "        # Get PR curve results\n",
    "        pr_df = get_pr_curve_results(\n",
    "            model=model, df=dataset, label=label, label_encoder=label_encoder\n",
    "        )\n",
    "        # Add model and dataset context\n",
    "        pr_df[\"model_type\"] = model_name\n",
    "        pr_df[\"dataset\"] = f\"test_{plate}\"\n",
    "        pr_df[\"plate_trained\"] = \"combined_batch1\"\n",
    "\n",
    "        # Append PR curve results\n",
    "        combined_model_split_test_pr_results.append(pr_df)\n",
    "\n",
    "        # Get predicted probabilities (per-sample) using the function\n",
    "        prob_df = get_predicted_probabilities(\n",
    "            model=model, df=dataset, label=label, label_encoder=label_encoder\n",
    "        )\n",
    "        # Add model and dataset context\n",
    "        prob_df[\"model_type\"] = model_name\n",
    "        prob_df[\"dataset\"] = f\"test_{plate}\"\n",
    "        prob_df[\"plate_trained\"] = \"combined_batch1\"\n",
    "\n",
    "        # Append predicted probabilities\n",
    "        combined_model_split_test_probability_results.append(prob_df)\n",
    "\n",
    "        # Print the shape of pr_df per test plate split\n",
    "        print(f\"{model_name} applied to {plate} shape: {pr_df.shape}\")\n",
    "\n",
    "# Combine all results into one dataframe for PR curve results and probabilities\n",
    "combined_model_split_test_pr_results_df = pd.concat(combined_model_split_test_pr_results, ignore_index=True)\n",
    "combined_model_split_test_probability_results_df = pd.concat(combined_model_split_test_probability_results, ignore_index=True)\n",
    "\n",
    "# Check the output\n",
    "print(f\"Final combined Probability DataFrame shape: {combined_model_split_test_probability_results_df.shape}\")\n",
    "combined_model_split_test_probability_results_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61390, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>plate_trained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.080243</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.044181</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.192410</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>failing</td>\n",
       "      <td>0.079217</td>\n",
       "      <td>DMSO</td>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  actual_label  predicted_probability Metadata_treatment model_type dataset  \\\n",
       "0      failing               0.080243               DMSO      final   train   \n",
       "1      failing               0.028664               DMSO      final   train   \n",
       "2      failing               0.044181               DMSO      final   train   \n",
       "3      failing               0.192410               DMSO      final   train   \n",
       "4      failing               0.079217               DMSO      final   train   \n",
       "\n",
       "           plate_trained  \n",
       "0  localhost240927120001  \n",
       "1  localhost240927120001  \n",
       "2  localhost240927120001  \n",
       "3  localhost240927120001  \n",
       "4  localhost240927120001  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all relevant DataFrames into one main DataFrame\n",
    "pr_results_df = pd.concat(\n",
    "    [train_test_all_models_pr_results_df, holdout_plate_individual_models_pr_df, combined_model_split_test_pr_results_df], ignore_index=True\n",
    ")\n",
    "probabilities_df = pd.concat(\n",
    "    [train_test_all_models_probabilities_df, holdout_plate_individual_models_probability_df, combined_model_split_test_probability_results_df], ignore_index=True\n",
    ")\n",
    "\n",
    "\n",
    "# Save the combined DataFrame as a parquet file\n",
    "pr_results_df.to_parquet(\n",
    "    f\"{performance_metrics_dir}/batch1_pr_curve_results.parquet\", index=False\n",
    ")\n",
    "probabilities_df.to_parquet(\n",
    "    f\"{performance_metrics_dir}/batch1_probabilities_DMSO_results.parquet\", index=False\n",
    ")\n",
    "\n",
    "# Check the shape of the final DataFrame\n",
    "print(probabilities_df.shape)\n",
    "probabilities_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibrosis_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
