{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract model performance metrics\n",
    "\n",
    "In this notebook, we extract metrics to evaluate performance such as:\n",
    "\n",
    "1. Precision-recall\n",
    "2. Predicted probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from joblib import load\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "sys.path.append(\"../utils\")\n",
    "from training_utils import get_X_y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directory with the training and testing datasets per plate (or combined per batch)\n",
    "data_dir = pathlib.Path(\"data\")\n",
    "\n",
    "# Directory with the trained models\n",
    "model_dir = pathlib.Path(\"models\")\n",
    "\n",
    "# Directory with encoder\n",
    "encoder_dir = pathlib.Path(\"encoder_results\")\n",
    "\n",
    "# Directory with the training indices\n",
    "train_indices_dir = pathlib.Path(\"training_indices\")\n",
    "\n",
    "# Directory with the normalized datasets\n",
    "normalized_data_path = pathlib.Path(\"../3.preprocessing_features/data/single_cell_profiles\")\n",
    "\n",
    "# Output directory the performance metrics\n",
    "performance_metrics_dir = pathlib.Path(\"performance_metrics\")\n",
    "performance_metrics_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dictionary with all relevant paths per plate to extract metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of encoder files\n",
    "encoder_files = list(encoder_dir.glob(\"label_encoder*\"))\n",
    "\n",
    "# Extract plate names by removing the 'label_encoder' prefix\n",
    "plate_names = [file.stem.replace(\"label_encoder_\", \"\") for file in encoder_files]\n",
    "\n",
    "# Create a nested dictionary with info per plate\n",
    "plates_dict = {}\n",
    "for plate in plate_names:\n",
    "    plates_dict[plate] = {\n",
    "        \"training_data\": data_dir / f\"{plate}_train.parquet\",\n",
    "        \"testing_data\": data_dir / f\"{plate}_test.parquet\",\n",
    "        \"final_model\": model_dir / f\"{plate}_final_downsample.joblib\",\n",
    "        \"shuffled_model\": model_dir / f\"{plate}_shuffled_downsample.joblib\",\n",
    "        \"encoder_result\": encoder_dir / f\"label_encoder_{plate}.joblib\",\n",
    "        \"training_indices\": train_indices_dir / f\"{plate}_training_data_indices.csv\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract metrics from the train and testing datasets applied to their respective plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "localhost240927120001: train shape: (536, 664)\n",
      "localhost240927120001: test shape: (455, 664)\n",
      "combined_batch1: train shape: (2408, 474)\n",
      "combined_batch1: test shape: (1991, 474)\n",
      "localhost240928120001: train shape: (572, 621)\n",
      "localhost240928120001: test shape: (472, 621)\n",
      "localhost240927060001: train shape: (422, 632)\n",
      "localhost240927060001: test shape: (458, 632)\n",
      "localhost240926150001: train shape: (878, 637)\n",
      "localhost240926150001: test shape: (607, 637)\n",
      "(17593, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>plate_trained</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.080243</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>0.500935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type dataset          plate_trained actual_label  \\\n",
       "0      final   train  localhost240927120001      failing   \n",
       "1      final   train  localhost240927120001      failing   \n",
       "\n",
       "   predicted_probability  precision  recall Metadata_treatment  \n",
       "0               0.080243   0.500000     1.0               DMSO  \n",
       "1               0.028664   0.500935     1.0               DMSO  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label being predicted\n",
    "label = \"Metadata_cell_type\"\n",
    "\n",
    "# Initialize results list\n",
    "pr_results = []\n",
    "\n",
    "# Iterate through each plate\n",
    "for plate, paths in plates_dict.items():\n",
    "    # Load models\n",
    "    final_model = load(paths[\"final_model\"])\n",
    "    shuffled_model = load(paths[\"shuffled_model\"])\n",
    "    \n",
    "    # Load encoder\n",
    "    label_encoder = load(paths[\"encoder_result\"])\n",
    "    \n",
    "    # Load data\n",
    "    train_df = pd.read_parquet(paths[\"training_data\"])\n",
    "    test_df = pd.read_parquet(paths[\"testing_data\"])\n",
    "    \n",
    "    # Load training indices for filtering training data\n",
    "    training_indices = pd.read_csv(paths[\"training_indices\"])[\"Index\"]\n",
    "    train_df_filtered = train_df.loc[training_indices]\n",
    "    \n",
    "    # Define datasets\n",
    "    datasets = {\"train\": train_df_filtered, \"test\": test_df}\n",
    "    \n",
    "    for dataset_name, dataset in datasets.items():\n",
    "        # Retain Metadata_treatment before collecting X and y data\n",
    "        metadata_treatment = dataset[\"Metadata_treatment\"].values \n",
    "        # Extract features and labels\n",
    "        X, y = get_X_y_data(df=dataset, label=label, shuffle=False)\n",
    "        print(f\"{plate}: {dataset_name} shape:\", X.shape, )\n",
    "\n",
    "        # Encode the labels\n",
    "        y_encoded = label_encoder.transform(y)\n",
    "\n",
    "        for model_name, model in [(\"final\", final_model), (\"shuffled\", shuffled_model)]:\n",
    "            # Predict probabilities for each cell\n",
    "            y_scores = model.predict_proba(X)[:, 1]  # Assuming binary classification\n",
    "\n",
    "            # Compute PR curve\n",
    "            precision, recall, _ = precision_recall_curve(y_encoded, y_scores)\n",
    "            \n",
    "            # Append results, ensuring each row represents a single cell\n",
    "            for actual, pred_prob, p, r, treatment in zip(y, y_scores, precision, recall, metadata_treatment):\n",
    "                pr_results.append({\n",
    "                    \"model_type\": model_name,\n",
    "                    \"dataset\": dataset_name,\n",
    "                    \"plate_trained\": plate,\n",
    "                    \"actual_label\": actual,\n",
    "                    \"predicted_probability\": pred_prob,\n",
    "                    \"precision\": p,\n",
    "                    \"recall\": r,\n",
    "                    \"Metadata_treatment\": treatment\n",
    "                })\n",
    "\n",
    "# Convert results to a single dataframe\n",
    "combined_train_test_df = pd.DataFrame(pr_results)\n",
    "\n",
    "# Check output\n",
    "print(combined_train_test_df.shape)\n",
    "combined_train_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plate models (final & shuffled) being applied is: localhost240927120001\n",
      "Plate models (final & shuffled) being applied is: localhost240928120001\n",
      "Plate models (final & shuffled) being applied is: localhost240927060001\n",
      "Plate models (final & shuffled) being applied is: localhost240926150001\n",
      "Plate: localhost240927120001, Shape: (10242, 8)\n",
      "Plate: localhost240928120001, Shape: (10120, 8)\n",
      "Plate: localhost240927060001, Shape: (10212, 8)\n",
      "Plate: localhost240926150001, Shape: (9218, 8)\n",
      "(39792, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>plate_trained</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>final</td>\n",
       "      <td>holdout_localhost240928120001</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.972434</td>\n",
       "      <td>0.259377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>final</td>\n",
       "      <td>holdout_localhost240928120001</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.996051</td>\n",
       "      <td>0.259542</td>\n",
       "      <td>1.0</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                        dataset actual_label  \\\n",
       "0      final  holdout_localhost240928120001      healthy   \n",
       "1      final  holdout_localhost240928120001      healthy   \n",
       "\n",
       "   predicted_probability  precision  recall          plate_trained  \\\n",
       "0               0.972434   0.259377     1.0  localhost240927120001   \n",
       "1               0.996051   0.259542     1.0  localhost240927120001   \n",
       "\n",
       "  Metadata_treatment  \n",
       "0               DMSO  \n",
       "1               DMSO  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through each plate\n",
    "cross_plate_results = {}\n",
    "\n",
    "for plate, paths in plates_dict.items():\n",
    "    if plate == \"combined_batch1\":\n",
    "        continue  # Skip the combined_batch1 plate\n",
    "\n",
    "    # Print current plate models being applied\n",
    "    print(f\"Plate models (final & shuffled) being applied is: {plate}\")\n",
    "\n",
    "    cross_plate_results[plate] = []  # Initialize an empty list for each plate\n",
    "\n",
    "    # Load models\n",
    "    final_model = load(paths[\"final_model\"])\n",
    "    shuffled_model = load(paths[\"shuffled_model\"])\n",
    "\n",
    "    # Load encoder\n",
    "    label_encoder = load(paths[\"encoder_result\"])\n",
    "\n",
    "    # Get the feature names from the model\n",
    "    model_features = final_model.feature_names_in_\n",
    "\n",
    "    # Iterate over other plates using normalized data (holdout sets)\n",
    "    for other_plate in plates_dict:\n",
    "        if other_plate == plate or other_plate == \"combined_batch1\":\n",
    "            continue  # Skip the same plate and combined_batch1\n",
    "\n",
    "        other_normalized_path = f\"{normalized_data_path}/{other_plate}_sc_normalized.parquet\"\n",
    "        other_combined_df = pd.read_parquet(other_normalized_path)\n",
    "\n",
    "        # Filter out only the cells with Metadata_treatment as DMSO\n",
    "        other_combined_df = other_combined_df[other_combined_df[\"Metadata_treatment\"] == \"DMSO\"]\n",
    "\n",
    "        # Drop rows with NaNs based on model features\n",
    "        other_combined_df_drop_nans = other_combined_df.dropna(subset=model_features)\n",
    "\n",
    "        # Get the metadata columns (those starting with 'Metadata_')\n",
    "        metadata_columns = [col for col in other_combined_df_drop_nans.columns if col.startswith('Metadata_')]\n",
    "\n",
    "        # Get model features that exist in the dataframe\n",
    "        model_features_in_df = [col for col in model_features if col in other_combined_df_drop_nans.columns]\n",
    "\n",
    "        # Filter the dataframe to keep only model features and metadata columns\n",
    "        other_combined_df_filtered = other_combined_df_drop_nans[metadata_columns + model_features_in_df]\n",
    "\n",
    "        # Retain Metadata_treatment before collecting X and y data\n",
    "        metadata_treatment = other_combined_df_filtered[\"Metadata_treatment\"].values \n",
    "\n",
    "        # Extract features and labels\n",
    "        X, y = get_X_y_data(df=other_combined_df_filtered, label=label)\n",
    "\n",
    "        # Assert that the columns in X match the features in the model\n",
    "        assert all(col in model_features for col in X\n",
    "                   ), \"Features in the model do not match the columns in the dataset\"\n",
    "\n",
    "        # Encode the labels\n",
    "        y_encoded = label_encoder.transform(y)\n",
    "\n",
    "        for model_name, model in [(\"final\", final_model), (\"shuffled\", shuffled_model)]:\n",
    "            # Predict probabilities\n",
    "            y_scores = model.predict_proba(X)[:, 1]\n",
    "\n",
    "            # Compute PR curve\n",
    "            precision, recall, thresholds = precision_recall_curve(y_encoded, y_scores)\n",
    "\n",
    "            # Append the results to the list associated with the plate\n",
    "            for actual, pred_prob, p, r, treatment in zip(y, y_scores, precision, recall, metadata_treatment):\n",
    "                cross_plate_results[plate].append({\n",
    "                    \"model_type\": model_name,\n",
    "                    \"dataset\": f\"holdout_{other_plate}\",  # mark these other plates as holdout\n",
    "                    \"actual_label\": actual,\n",
    "                    \"predicted_probability\": pred_prob,\n",
    "                    \"precision\": p,\n",
    "                    \"recall\": r,\n",
    "                    \"plate_trained\": plate,\n",
    "                    \"Metadata_treatment\": treatment\n",
    "                })\n",
    "                \n",
    "# Convert the results to DataFrame\n",
    "cross_plate_results_dfs = {\n",
    "    plate: pd.DataFrame(data) for plate, data in cross_plate_results.items()\n",
    "}\n",
    "\n",
    "# Print the shape of each DataFrame\n",
    "for plate, df in cross_plate_results_dfs.items():\n",
    "    print(f\"Plate: {plate}, Shape: {df.shape}\")\n",
    "\n",
    "# Combine all the dataframes into one dataframe and add a 'plate' column to track origin\n",
    "combined_holdout_df = pd.concat(cross_plate_results_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Check the output\n",
    "print(combined_holdout_df.shape)\n",
    "combined_holdout_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3982, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>plate_trained</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>final</td>\n",
       "      <td>test_localhost240926150001</td>\n",
       "      <td>healthy</td>\n",
       "      <td>0.995492</td>\n",
       "      <td>0.294314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>combined_batch1</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>final</td>\n",
       "      <td>test_localhost240926150001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.001508</td>\n",
       "      <td>0.294807</td>\n",
       "      <td>1.0</td>\n",
       "      <td>combined_batch1</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type                     dataset actual_label  predicted_probability  \\\n",
       "0      final  test_localhost240926150001      healthy               0.995492   \n",
       "1      final  test_localhost240926150001      failing               0.001508   \n",
       "\n",
       "   precision  recall    plate_trained Metadata_treatment  \n",
       "0   0.294314     1.0  combined_batch1               DMSO  \n",
       "1   0.294807     1.0  combined_batch1               DMSO  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Label being predicted\n",
    "label = \"Metadata_cell_type\"\n",
    "\n",
    "# Initialize results dictionary\n",
    "pr_results = {}\n",
    "\n",
    "# Only process the combined_batch1 data\n",
    "paths = plates_dict[\"combined_batch1\"]\n",
    "\n",
    "# Load models\n",
    "final_model = load(paths[\"final_model\"])\n",
    "shuffled_model = load(paths[\"shuffled_model\"])\n",
    "\n",
    "# Load encoder\n",
    "label_encoder = load(paths[\"encoder_result\"])\n",
    "\n",
    "# Load testing data\n",
    "test_df = pd.read_parquet(paths[\"testing_data\"])\n",
    "\n",
    "# Split testing data by Metadata_Plate\n",
    "test_groups = test_df.groupby(\"Metadata_Plate\")\n",
    "\n",
    "for plate, dataset in test_groups:\n",
    "    pr_results[plate] = []  # Initialize an empty list for each testing plate\n",
    "\n",
    "    # Retain Metadata_treatment before collecting X and y data\n",
    "    metadata_treatment = dataset[\"Metadata_treatment\"].values \n",
    "\n",
    "    # Extract features and labels\n",
    "    X, y = get_X_y_data(df=dataset, label=label, shuffle=False)\n",
    "\n",
    "    # Encode the labels\n",
    "    y_encoded = label_encoder.transform(y)\n",
    "\n",
    "    for model_name, model in [(\"final\", final_model), (\"shuffled\", shuffled_model)]:\n",
    "        # Predict probabilities\n",
    "        y_scores = model.predict_proba(X)[:, 1]  # Assuming binary classification\n",
    "\n",
    "        # Compute PR curve\n",
    "        precision, recall, _ = precision_recall_curve(y_encoded, y_scores)\n",
    "\n",
    "        # Store results as individual rows (one per precision-recall pair)\n",
    "        for actual, pred_prob, p, r, treatment in zip(y, y_scores, precision, recall, metadata_treatment):\n",
    "            pr_results[plate].append({\n",
    "                \"model_type\": model_name,\n",
    "                \"dataset\": f\"test_{plate}\",\n",
    "                \"actual_label\": actual,\n",
    "                \"predicted_probability\": pred_prob,\n",
    "                \"precision\": p,\n",
    "                \"recall\": r,\n",
    "                \"plate_trained\": \"combined_batch1\",\n",
    "                \"Metadata_treatment\": treatment\n",
    "            })\n",
    "            \n",
    "# Convert results to dataframes\n",
    "pr_results_dfs = {\n",
    "    plate: pd.DataFrame(data) for plate, data in pr_results.items()\n",
    "}\n",
    "\n",
    "# Combine all results into one dataframe\n",
    "combined_test_df = pd.concat(pr_results_dfs.values(), ignore_index=True)\n",
    "\n",
    "# Check the output\n",
    "print(combined_test_df.shape)\n",
    "combined_test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61367, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_type</th>\n",
       "      <th>dataset</th>\n",
       "      <th>plate_trained</th>\n",
       "      <th>actual_label</th>\n",
       "      <th>predicted_probability</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>Metadata_treatment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.080243</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.028664</td>\n",
       "      <td>0.500935</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.044181</td>\n",
       "      <td>0.501873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.192410</td>\n",
       "      <td>0.502814</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>final</td>\n",
       "      <td>train</td>\n",
       "      <td>localhost240927120001</td>\n",
       "      <td>failing</td>\n",
       "      <td>0.079217</td>\n",
       "      <td>0.503759</td>\n",
       "      <td>1.0</td>\n",
       "      <td>DMSO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_type dataset          plate_trained actual_label  \\\n",
       "0      final   train  localhost240927120001      failing   \n",
       "1      final   train  localhost240927120001      failing   \n",
       "2      final   train  localhost240927120001      failing   \n",
       "3      final   train  localhost240927120001      failing   \n",
       "4      final   train  localhost240927120001      failing   \n",
       "\n",
       "   predicted_probability  precision  recall Metadata_treatment  \n",
       "0               0.080243   0.500000     1.0               DMSO  \n",
       "1               0.028664   0.500935     1.0               DMSO  \n",
       "2               0.044181   0.501873     1.0               DMSO  \n",
       "3               0.192410   0.502814     1.0               DMSO  \n",
       "4               0.079217   0.503759     1.0               DMSO  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all relevant DataFrames into one main DataFrame\n",
    "performance_metrics_df = pd.concat(\n",
    "    [combined_train_test_df, combined_holdout_df, combined_test_df],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Save the combined DataFrame as a parquet file\n",
    "performance_metrics_df.to_parquet(f\"{performance_metrics_dir}/performance_metrics.parquet\", index=False)\n",
    "\n",
    "# Check the shape of the final DataFrame\n",
    "print(performance_metrics_df.shape)\n",
    "performance_metrics_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fibrosis_machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
